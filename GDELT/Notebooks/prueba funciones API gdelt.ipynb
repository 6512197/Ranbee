{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from gdeltdoc import GdeltDoc, Filters\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de la primera funcion de la API\n",
    "def get_articles(keyword: str, start_date: str, end_date: str, country: str):\n",
    "    f = Filters(keyword=keyword,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        country=country)\n",
    "    gd = GdeltDoc()\n",
    "    articles = gd.article_search(f)\n",
    "    df = pd.DataFrame(articles)\n",
    "    df.to_csv(\"csv_articulos.csv\") # si lo que queremos es que se nos descargue en el ordenador y obtener un mensaje de que se ha hecho bien\n",
    "    return df # lo hemos cambiado, para obtener un df!!! que antes con el 200:ok la funcion de limpieza no funcionaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  url  \\\n",
      "0   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "1   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "2   https://www.wallstreet-online.de/nachricht/167...   \n",
      "3   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "4   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "..                                                ...   \n",
      "69  https://www.finanznachrichten.de/nachrichten-2...   \n",
      "70  https://www.boersennews.de/nachrichten/artikel...   \n",
      "71  https://www.openpr.de/news/1244427/Einsatz-von...   \n",
      "72  https://www.nexotur.com/noticia/118383/colombi...   \n",
      "73  https://www.boersennews.de/nachrichten/artikel...   \n",
      "\n",
      "                                           url_mobile  \\\n",
      "0                                                       \n",
      "1                                                       \n",
      "2   https://www.wallstreet-online.de/_amp/nachrich...   \n",
      "3                                                       \n",
      "4                                                       \n",
      "..                                                ...   \n",
      "69                                                      \n",
      "70                                                      \n",
      "71                                                      \n",
      "72    https://www.nexotur.com/mvc/amp/noticia/118383/   \n",
      "73                                                      \n",
      "\n",
      "                                                title          seendate  \\\n",
      "0   The Mastercard Center for Inclusive Growth : H...  20230331T230000Z   \n",
      "1   The Mastercard Center for Inclusive Growth : S...  20230321T160000Z   \n",
      "2        How Mastercard Is Advancing Inclusive Growth  20230331T230000Z   \n",
      "3   The Mastercard Center for Inclusive Growth : H...  20230417T191500Z   \n",
      "4   The Mastercard Center for Inclusive Growth : J...  20230316T201500Z   \n",
      "..                                                ...               ...   \n",
      "69  EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...  20230330T134500Z   \n",
      "70  IRW - News : First Class Metals Plc .: First C...  20230309T124500Z   \n",
      "71  Einsatz von Nahrungsergänzungsmittel in Hochri...  20230426T090000Z   \n",
      "72  Colombia se define como un destino biodiverso ...  20230216T064500Z   \n",
      "73  EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...  20230330T134500Z   \n",
      "\n",
      "                                          socialimage                domain  \\\n",
      "0   https://www.finanznachrichten.de/chart-masterc...  finanznachrichten.de   \n",
      "1   https://www.finanznachrichten.de/chart-masterc...  finanznachrichten.de   \n",
      "2   https://assets.wallstreet-online.de/_media/126...  wallstreet-online.de   \n",
      "3   https://www.accesswire.com/users/newswire/imag...  finanznachrichten.de   \n",
      "4   https://www.accesswire.com/users/newswire/imag...  finanznachrichten.de   \n",
      "..                                                ...                   ...   \n",
      "69  https://eqs-cockpit.com/cgi-bin/fncls.ssp?fn=s...  finanznachrichten.de   \n",
      "70  https://media.boersennews.de/images/news/austi...        boersennews.de   \n",
      "71  https://cdn.openpr.de/pressemitteilung/c/1/6/c...             openpr.de   \n",
      "72  https://www.nexotur.com/fotos/1/Arturo_Bravo_V...           nexotur.com   \n",
      "73  https://media.boersennews.de/images/news/woman...        boersennews.de   \n",
      "\n",
      "   language sourcecountry  \n",
      "0   English       Germany  \n",
      "1   English       Germany  \n",
      "2   English       Germany  \n",
      "3   English       Germany  \n",
      "4   English       Germany  \n",
      "..      ...           ...  \n",
      "69   German       Germany  \n",
      "70   German       Germany  \n",
      "71   German       Germany  \n",
      "72  Spanish         Spain  \n",
      "73   German       Germany  \n",
      "\n",
      "[74 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(get_articles(\"Inclusive growth\",\"2018-05-10\",\"2023-05-11\",[\"Austria\",\"Belgium\",\"Switzerland\",\"Cyprus\",\"Germany\",\"Denmark\",\"Estonia\",\"Spain\"]))\n",
    "# FUNCIONA, descarga el csv\n",
    "# IMPORTANTE, TENEMOS QUE INCLUIR UNA FORMA PARA NO SOBREESCRIBIR LOS ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFICACION AÑADIDA, cambiar en el original\n",
    "def get_articles(keyword: str, start_date: str, end_date: str, country: str):\n",
    "    f = Filters(keyword=keyword,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        country=country)\n",
    "    gd = GdeltDoc()\n",
    "    articles = gd.article_search(f)\n",
    "    df = pd.DataFrame(articles)\n",
    "    file_number = 1  # Comprobamos si el archivo ya existe CON EL BUCLE WHILE\n",
    "    while os.path.exists(f\"csv_articulos_{file_number}.csv\"):\n",
    "        file_number += 1\n",
    "    filename = f\"csv_articulos_{file_number}.csv\"\n",
    "    df.to_csv(filename, index=False) \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  url  \\\n",
      "0   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "1   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "2   https://www.wallstreet-online.de/nachricht/167...   \n",
      "3   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "4   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "..                                                ...   \n",
      "69  https://www.finanznachrichten.de/nachrichten-2...   \n",
      "70  https://www.boersennews.de/nachrichten/artikel...   \n",
      "71  https://www.openpr.de/news/1244427/Einsatz-von...   \n",
      "72  https://www.nexotur.com/noticia/118383/colombi...   \n",
      "73  https://www.boersennews.de/nachrichten/artikel...   \n",
      "\n",
      "                                           url_mobile  \\\n",
      "0                                                       \n",
      "1                                                       \n",
      "2   https://www.wallstreet-online.de/_amp/nachrich...   \n",
      "3                                                       \n",
      "4                                                       \n",
      "..                                                ...   \n",
      "69                                                      \n",
      "70                                                      \n",
      "71                                                      \n",
      "72    https://www.nexotur.com/mvc/amp/noticia/118383/   \n",
      "73                                                      \n",
      "\n",
      "                                                title          seendate  \\\n",
      "0   The Mastercard Center for Inclusive Growth : H...  20230331T230000Z   \n",
      "1   The Mastercard Center for Inclusive Growth : S...  20230321T160000Z   \n",
      "2        How Mastercard Is Advancing Inclusive Growth  20230331T230000Z   \n",
      "3   The Mastercard Center for Inclusive Growth : H...  20230417T191500Z   \n",
      "4   The Mastercard Center for Inclusive Growth : J...  20230316T201500Z   \n",
      "..                                                ...               ...   \n",
      "69  EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...  20230330T134500Z   \n",
      "70  IRW - News : First Class Metals Plc .: First C...  20230309T124500Z   \n",
      "71  Einsatz von Nahrungsergänzungsmittel in Hochri...  20230426T090000Z   \n",
      "72  Colombia se define como un destino biodiverso ...  20230216T064500Z   \n",
      "73  EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...  20230330T134500Z   \n",
      "\n",
      "                                          socialimage                domain  \\\n",
      "0   https://www.finanznachrichten.de/chart-masterc...  finanznachrichten.de   \n",
      "1   https://www.finanznachrichten.de/chart-masterc...  finanznachrichten.de   \n",
      "2   https://assets.wallstreet-online.de/_media/126...  wallstreet-online.de   \n",
      "3   https://www.accesswire.com/users/newswire/imag...  finanznachrichten.de   \n",
      "4   https://www.accesswire.com/users/newswire/imag...  finanznachrichten.de   \n",
      "..                                                ...                   ...   \n",
      "69  https://eqs-cockpit.com/cgi-bin/fncls.ssp?fn=s...  finanznachrichten.de   \n",
      "70  https://media.boersennews.de/images/news/austi...        boersennews.de   \n",
      "71  https://cdn.openpr.de/pressemitteilung/c/1/6/c...             openpr.de   \n",
      "72  https://www.nexotur.com/fotos/1/Arturo_Bravo_V...           nexotur.com   \n",
      "73  https://media.boersennews.de/images/news/woman...        boersennews.de   \n",
      "\n",
      "   language sourcecountry  \n",
      "0   English       Germany  \n",
      "1   English       Germany  \n",
      "2   English       Germany  \n",
      "3   English       Germany  \n",
      "4   English       Germany  \n",
      "..      ...           ...  \n",
      "69   German       Germany  \n",
      "70   German       Germany  \n",
      "71   German       Germany  \n",
      "72  Spanish         Spain  \n",
      "73   German       Germany  \n",
      "\n",
      "[74 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(get_articles(\"Inclusive growth\",\"2018-05-10\",\"2023-05-11\",[\"Austria\",\"Belgium\",\"Switzerland\",\"Cyprus\",\"Germany\",\"Denmark\",\"Estonia\",\"Spain\"]))\n",
    "# HACEMOS LA PRUEBA Y FUNCIONA!! CAMBIARLO EN EL FINAL DEL REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUEBA FER, AÑADIR PARAMETRO PARA EVITAR O NO LA DESCARGA DEL CSV\n",
    "def get_articles(keyword: str, start_date: str, end_date: str, country: str, descarga: str):\n",
    "    f = Filters(keyword=keyword,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        country=country)\n",
    "    gd = GdeltDoc()\n",
    "    articles = gd.article_search(f)\n",
    "    df = pd.DataFrame(articles)\n",
    "    file_number = 1  # Comprobamos si el archivo ya existe CON EL BUCLE WHILE\n",
    "    while os.path.exists(f\"csv_articulos_{file_number}.csv\"):\n",
    "        file_number += 1\n",
    "    filename = f\"csv_articulos_{file_number}.csv\"\n",
    "    if descarga == \"yes\":\n",
    "        df.to_csv(filename, index=False) \n",
    "        return df\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "# creamos un nuevo parametro, descarga, Y SI ES SI SE DESCARGA Y SI NO, COMO PARA LOS ENDPOINTS DE LIMPIEZA NO SE DESCARGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  url  \\\n",
      "0   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "1   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "2   https://www.wallstreet-online.de/nachricht/167...   \n",
      "3   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "4   https://www.finanznachrichten.de/nachrichten-2...   \n",
      "..                                                ...   \n",
      "69  https://www.finanznachrichten.de/nachrichten-2...   \n",
      "70  https://www.boersennews.de/nachrichten/artikel...   \n",
      "71  https://www.openpr.de/news/1244427/Einsatz-von...   \n",
      "72  https://www.nexotur.com/noticia/118383/colombi...   \n",
      "73  https://www.boersennews.de/nachrichten/artikel...   \n",
      "\n",
      "                                           url_mobile  \\\n",
      "0                                                       \n",
      "1                                                       \n",
      "2   https://www.wallstreet-online.de/_amp/nachrich...   \n",
      "3                                                       \n",
      "4                                                       \n",
      "..                                                ...   \n",
      "69                                                      \n",
      "70                                                      \n",
      "71                                                      \n",
      "72    https://www.nexotur.com/mvc/amp/noticia/118383/   \n",
      "73                                                      \n",
      "\n",
      "                                                title          seendate  \\\n",
      "0   The Mastercard Center for Inclusive Growth : H...  20230331T230000Z   \n",
      "1   The Mastercard Center for Inclusive Growth : S...  20230321T160000Z   \n",
      "2        How Mastercard Is Advancing Inclusive Growth  20230331T230000Z   \n",
      "3   The Mastercard Center for Inclusive Growth : H...  20230417T191500Z   \n",
      "4   The Mastercard Center for Inclusive Growth : J...  20230316T201500Z   \n",
      "..                                                ...               ...   \n",
      "69  EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...  20230330T134500Z   \n",
      "70  IRW - News : First Class Metals Plc .: First C...  20230309T124500Z   \n",
      "71  Einsatz von Nahrungsergänzungsmittel in Hochri...  20230426T090000Z   \n",
      "72  Colombia se define como un destino biodiverso ...  20230216T064500Z   \n",
      "73  EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...  20230330T134500Z   \n",
      "\n",
      "                                          socialimage                domain  \\\n",
      "0   https://www.finanznachrichten.de/chart-masterc...  finanznachrichten.de   \n",
      "1   https://www.finanznachrichten.de/chart-masterc...  finanznachrichten.de   \n",
      "2   https://assets.wallstreet-online.de/_media/126...  wallstreet-online.de   \n",
      "3   https://www.accesswire.com/users/newswire/imag...  finanznachrichten.de   \n",
      "4   https://www.accesswire.com/users/newswire/imag...  finanznachrichten.de   \n",
      "..                                                ...                   ...   \n",
      "69  https://eqs-cockpit.com/cgi-bin/fncls.ssp?fn=s...  finanznachrichten.de   \n",
      "70  https://media.boersennews.de/images/news/austi...        boersennews.de   \n",
      "71  https://cdn.openpr.de/pressemitteilung/c/1/6/c...             openpr.de   \n",
      "72  https://www.nexotur.com/fotos/1/Arturo_Bravo_V...           nexotur.com   \n",
      "73  https://media.boersennews.de/images/news/woman...        boersennews.de   \n",
      "\n",
      "   language sourcecountry  \n",
      "0   English       Germany  \n",
      "1   English       Germany  \n",
      "2   English       Germany  \n",
      "3   English       Germany  \n",
      "4   English       Germany  \n",
      "..      ...           ...  \n",
      "69   German       Germany  \n",
      "70   German       Germany  \n",
      "71   German       Germany  \n",
      "72  Spanish         Spain  \n",
      "73   German       Germany  \n",
      "\n",
      "[74 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(get_articles(\"Inclusive growth\",\"2018-05-10\",\"2023-05-11\",[\"Austria\",\"Belgium\",\"Switzerland\",\"Cyprus\",\"Germany\",\"Denmark\",\"Estonia\",\"Spain\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra prueba, esta vez con LA FUNCION tono, A LA QUE HAY QUE AÑADIRLE LO MISMO DE LOS ARTICULOS PARA EVITAR SOBREESCRIBIR\n",
    "# añadimos el cambio de Fer, con el parametro para descargar o no\n",
    "def get_tone_results(keyword: str, start_date: str, end_date: str, country: str):\n",
    "    f = Filters(keyword=keyword,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        country=country)\n",
    "    gd = GdeltDoc()\n",
    "    tone_results = gd.timeline_search(\"timelinetone\", f)\n",
    "    df_tono = pd.DataFrame(tone_results)\n",
    "    file_number = 1  # Comprobamos si el archivo ya existe CON EL BUCLE WHILE\n",
    "    while os.path.exists(f\"csv_tono_{file_number}.csv\"):\n",
    "        file_number += 1\n",
    "    filename = f\"csv_tono_{file_number}.csv\"\n",
    "    if descarga == \"yes\":\n",
    "        df_tono.to_csv(filename, index=False) \n",
    "        return df_tono\n",
    "    else:\n",
    "        return df_tono # lo cambiamos para obtener un df que podamos usar en la funcion de limpieza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      datetime  Average Tone\n",
      "0    2018-05-10 00:00:00+00:00        0.0000\n",
      "1    2018-05-11 00:00:00+00:00        0.0000\n",
      "2    2018-05-12 00:00:00+00:00        0.0000\n",
      "3    2018-05-13 00:00:00+00:00        0.0000\n",
      "4    2018-05-14 00:00:00+00:00       -0.6656\n",
      "...                        ...           ...\n",
      "1821 2023-05-07 00:00:00+00:00        0.0000\n",
      "1822 2023-05-08 00:00:00+00:00        2.5937\n",
      "1823 2023-05-09 00:00:00+00:00        0.0000\n",
      "1824 2023-05-10 00:00:00+00:00       -3.4895\n",
      "1825 2023-05-11 00:00:00+00:00        0.0000\n",
      "\n",
      "[1826 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(get_tone_results(\"Inclusive growth\",\"2018-05-10\",\"2023-05-11\",[\"Austria\",\"Belgium\",\"Switzerland\",\"Cyprus\",\"Germany\",\"Denmark\",\"Estonia\",\"Spain\"],\"yes\"))\n",
    "# funciona tambien, asi que genial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion popularidad, mismo cambio para que no se sobreescriban,, y creacion del bucle con el parametro \n",
    "# descarga para elegir si obtener el csv o no\n",
    "def get_popularity_results(keyword: str, start_date: str, end_date: str, country: str):\n",
    "    f = Filters( keyword=keyword,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        country=country)\n",
    "    gd = GdeltDoc()\n",
    "    popularity_results = gd.timeline_search(\"timelinesourcecountry\", f) # CAMBIAMOS timelinevoL POR timelinesourcecountry PARA QUE DIVIDAN POR PAISES\n",
    "    df_popularidad = pd.DataFrame(popularity_results)\n",
    "    file_number = 1  # Comprobamos si el archivo ya existe CON EL BUCLE WHILE\n",
    "    while os.path.exists(f\"csv_popularidad_{file_number}.csv\"):\n",
    "        file_number += 1\n",
    "    filename = f\"csv_popularidad_{file_number}.csv\"\n",
    "    if descarga == \"yes\":\n",
    "        df_popularidad.to_csv(filename, index=False) \n",
    "        return df_popularidad\n",
    "    else:\n",
    "        return df_popularidad # lo cambiamos para obtener un df que podamos usar en la funcion de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      datetime  Volume Intensity\n",
      "0    2018-05-10 00:00:00+00:00            0.0000\n",
      "1    2018-05-11 00:00:00+00:00            0.0000\n",
      "2    2018-05-12 00:00:00+00:00            0.0000\n",
      "3    2018-05-13 00:00:00+00:00            0.0000\n",
      "4    2018-05-14 00:00:00+00:00            0.0002\n",
      "...                        ...               ...\n",
      "1821 2023-05-07 00:00:00+00:00            0.0000\n",
      "1822 2023-05-08 00:00:00+00:00            0.0006\n",
      "1823 2023-05-09 00:00:00+00:00            0.0000\n",
      "1824 2023-05-10 00:00:00+00:00            0.0005\n",
      "1825 2023-05-11 00:00:00+00:00            0.0000\n",
      "\n",
      "[1826 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(get_popularity_results(\"Inclusive growth\",\"2018-05-10\",\"2023-05-11\",[\"Austria\",\"Belgium\",\"Switzerland\",\"Cyprus\",\"Germany\",\"Denmark\",\"Estonia\",\"Spain\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA LA FUNCION DE LIMPIEZA, FUNCION AUXILIAR\n",
    "def limpiar_dataframe(df: pd.DataFrame):\n",
    "    df_limpio= df.dropna().drop_duplicates()\n",
    "    return df_limpio # creo la funcion primero, que luego podre usar para cualquier DataFrame. Metemos solo los nulos y duplicados en un primer momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a coger un DataFrame para probar la funcion\n",
    "df = pd.read_csv(\"csv_articulos_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74 entries, 0 to 73\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   url            74 non-null     object\n",
      " 1   url_mobile     21 non-null     object\n",
      " 2   title          74 non-null     object\n",
      " 3   seendate       74 non-null     object\n",
      " 4   socialimage    64 non-null     object\n",
      " 5   domain         74 non-null     object\n",
      " 6   language       74 non-null     object\n",
      " 7   sourcecountry  74 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limpio = limpiar_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18 entries, 2 to 72\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   url            18 non-null     object\n",
      " 1   url_mobile     18 non-null     object\n",
      " 2   title          18 non-null     object\n",
      " 3   seendate       18 non-null     object\n",
      " 4   socialimage    18 non-null     object\n",
      " 5   domain         18 non-null     object\n",
      " 6   language       18 non-null     object\n",
      " 7   sourcecountry  18 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "limpio.info()\n",
    "# OJO, LA FUNCION FUNCIONA, PERO QUITANDO LOS NULOS Y DUPLICADOS HEMOS PERDIDO MUCHISIMOS REGISTROS.\n",
    "# LA COLUMNA URL_MOBILE TIENE SOLO 21 REGISTROS Y ESO YA NOS QUITA MUCHISIMOS.\n",
    "# REVISAR ESTO y si tenemos que eliminar columnas con mas de una cantidad de nulos en lugar de las filas,\n",
    "# poner un threshold de la cantidad de nulos que nos hará eliminar una columna, con que sustituir los nulos en caso \n",
    "# de que se mantenga..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint para limpiar los datos (este incluiría solo estas tres funciones), no se si podríamos hacerlo en general\n",
    "def endpoint_limpiar_dataframe(funcion_obtener_datos: str, keyword: str, start_date: str, end_date: str, country: str,descarga: str): # LOS PARAMETROS NECESARIOS\n",
    "    if funcion_obtener_datos == \"articles\":\n",
    "        df = get_articles(keyword, start_date, end_date, country,descarga)\n",
    "    elif funcion_obtener_datos == \"tone\":\n",
    "        df = get_tone_results(keyword, start_date, end_date, country,descarga)\n",
    "    elif funcion_obtener_datos == \"popularity\":\n",
    "        df = get_popularity_results(keyword, start_date, end_date, country,descarga)\n",
    "    else:\n",
    "        return {\"mensaje\": \"Función de obtener datos no válida\"}\n",
    "    \n",
    "    df_limpio = limpiar_dataframe(df)\n",
    "    file_number = 1 # USAMOS EL MISMO BUCLE QUE LOS ENPOINTS PARA EVITAR SOBREESCRIBIR\n",
    "    while os.path.exists(f\"csv_{funcion_obtener_datos}_limpios_{file_number}.csv\"):\n",
    "        file_number += 1\n",
    "    filename = f\"csv_{funcion_obtener_datos}_limpios_{file_number}.csv\" \n",
    "    \n",
    "    df_limpio.to_csv(filename, index=False)\n",
    "     \n",
    "    return {\"mensaje\": f\"Datos de {funcion_obtener_datos} limpiados y guardados exitosamente en '{filename}'\"}\n",
    "\n",
    "# ASI SE DESCARGAN TANTO LIMPIOS COMO SUCIOS, AL USAR LAS LLAMADAS GET ARTICLES, GET TONE Y GET POPULARITY, LA DESCARGA\n",
    "# DEL CSV SUCEDE IGUAL. PREGUNTAR SI DEBERIAMOS CREAR UN NUEVO ENDPOINT QUE NO DESCARGUE EL ARCHIVO SUCIO, SI NO SOLO EL DF!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mendpoint_limpiar_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnemployement Benefits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2018-05-10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023-05-11\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAustria\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBelgium\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSwitzerland\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCyprus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGermany\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDenmark\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEstonia\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSpain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# da este error, porque hemos olvidado que lo que nos dan las funciones get articles, get tone y get popularity \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# son csvs descargados en nuestro ordenador, NO EL DATAFRAME QUE NECESITAMOS, HAY QUE CAMBIAR EL CODIGO DE LA FUNCION Y LA LLAMADA\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# DE LIMPIEZA.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# YA LOS HE CAMBIADO, HE PUESTO QUE LOS RETURN DE LOS OTROS ENDPOINTS SEAN UN DATAFRAME EN LUGAR DE LA NOTA ANTERIOR DE ARCHIVO DESCARGADO\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m, in \u001b[0;36mendpoint_limpiar_dataframe\u001b[1;34m(funcion_obtener_datos, keyword, start_date, end_date, country, descarga)\u001b[0m\n\u001b[0;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m get_articles(keyword, start_date, end_date, country,descarga)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m funcion_obtener_datos \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mget_tone_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcountry\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdescarga\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m funcion_obtener_datos \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopularity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      8\u001b[0m     df \u001b[38;5;241m=\u001b[39m get_popularity_results(keyword, start_date, end_date, country,descarga)\n",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m, in \u001b[0;36mget_tone_results\u001b[1;34m(keyword, start_date, end_date, country, descarga)\u001b[0m\n\u001b[0;32m      4\u001b[0m f \u001b[38;5;241m=\u001b[39m Filters(keyword\u001b[38;5;241m=\u001b[39mkeyword,\n\u001b[0;32m      5\u001b[0m     start_date\u001b[38;5;241m=\u001b[39mstart_date,\n\u001b[0;32m      6\u001b[0m     end_date\u001b[38;5;241m=\u001b[39mend_date,\n\u001b[0;32m      7\u001b[0m     country\u001b[38;5;241m=\u001b[39mcountry)\n\u001b[0;32m      8\u001b[0m gd \u001b[38;5;241m=\u001b[39m GdeltDoc()\n\u001b[1;32m----> 9\u001b[0m tone_results \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeline_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimelinetone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m df_tono \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tone_results)\n\u001b[0;32m     11\u001b[0m file_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Comprobamos si el archivo ya existe CON EL BUCLE WHILE\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Picar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gdeltdoc\\api_client.py:108\u001b[0m, in \u001b[0;36mGdeltDoc.timeline_search\u001b[1;34m(self, mode, filters)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03mMake a query using one of the API's timeline modes.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    A pandas DataFrame of the articles returned from the API.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m timeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(mode, filters\u001b[38;5;241m.\u001b[39mquery_string)\n\u001b[1;32m--> 108\u001b[0m results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m: [entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtimeline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]]}\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m series \u001b[38;5;129;01min\u001b[39;00m timeline[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeline\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    111\u001b[0m     results[series[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m [entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m series[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timeline'"
     ]
    }
   ],
   "source": [
    "endpoint_limpiar_dataframe(\"tone\",\"Unemployement Benefits\",\"2018-05-10\",\"2023-05-11\",[\"Austria\",\"Belgium\",\"Switzerland\",\"Cyprus\",\"Germany\",\"Denmark\",\"Estonia\",\"Spain\"],\"no\")\n",
    "# da este error, porque hemos olvidado que lo que nos dan las funciones get articles, get tone y get popularity \n",
    "# son csvs descargados en nuestro ordenador, NO EL DATAFRAME QUE NECESITAMOS, HAY QUE CAMBIAR EL CODIGO DE LA FUNCION Y LA LLAMADA\n",
    "# DE LIMPIEZA.\n",
    "# YA LOS HE CAMBIADO, HE PUESTO QUE LOS RETURN DE LOS OTROS ENDPOINTS SEAN UN DATAFRAME EN LUGAR DE LA NOTA ANTERIOR DE ARCHIVO DESCARGADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YA HEMOS METIDO EL BUCLE PARA EVITAR QUE SE DESCARGUE EL DATASET EN SUCIO EN LA LIMPIEZA "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
