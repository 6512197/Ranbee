{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdeltdoc in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdeltdoc) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.25.1 in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdeltdoc) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\picar\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.1.4->gdeltdoc) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.1.4->gdeltdoc) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.1.4->gdeltdoc) (1.26.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.25.1->gdeltdoc) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.25.1->gdeltdoc) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.25.1->gdeltdoc) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\picar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.25.1->gdeltdoc) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\picar\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->gdeltdoc) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# PRUEBA GDELTDOC, EJEMPLO de uno de los topics\n",
    "!pip install gdeltdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeltdoc import GdeltDoc, Filters\n",
    "import pandas as pd\n",
    "f = Filters(\n",
    "    keyword=\"Inclusive growth\",\n",
    "    start_date=\"2018-05-10\", # primero he puesto 2014, PERO ME DABA ERROR COMO SI DE ESTE TOPIC NO HUBIESE TODOS LOS AÑOS!!!  REVISAR ESTO!\n",
    "    end_date=\"2023-05-11\",\n",
    "    country = [\"Austria\",\"Belgium\",\"Switzerland\",\"Cyprus\",\"Czech Republic\", \"Germany\",\"Denmark\",\"Estonia\",\"Greece\", \"Spain\",\"Finland\",\"France\",\"Hungary\",\"Ireland\",\"Iceland\",\"Italy\",\"Luxembourg\",\"Montenegro\",\"Malta\",\"Netherlands\",\"Norway\",\"Poland\",\"Portugal\",\"Sweden\",\"Slovenia\",\"United Kingdom\",\"Lithuania\",\"Latvia\"]\n",
    ")\n",
    "\n",
    "# Para meter filtro PAISES, parametro country, NOMBRE COMPLETO DEL PAIS EN INGLES, en esta pagina salen todos los parametros https://pypi.org/project/gdeltdoc/\n",
    "# NO HE VISTO NINGUN PARAMETRO PARA EL NUMERO DE PALABRAS (hemos probado min_words, pero no funciona)\n",
    "# Podemos filtrar una vez encontrados, encontramos una forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizar la consulta\n",
    "documents = GdeltDoc().documents(f)\n",
    "\n",
    "# Filtrar los documentos por longitud de palabras\n",
    "filtered_documents = [doc for doc in documents if len(doc['content'].split()) > 500]\n",
    "df = pd.DataFrame(filtered_documents) # pasando a dataframe solo los filtrados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The query was not valid. The API error message was: Your query was too short or too long.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m gd \u001b[38;5;241m=\u001b[39m GdeltDoc()\n\u001b[1;32m----> 2\u001b[0m articles \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marticle_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(articles)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# con toda la lista de paises no es posible, sale error, habrá que hacerlos en bloques\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Picar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gdeltdoc\\api_client.py:79\u001b[0m, in \u001b[0;36mGdeltDoc.article_search\u001b[1;34m(self, filters)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marticle_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, filters: Filters) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Make a query against the `ArtList` API to return a DataFrame of news articles that\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    match the supplied filters.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m        A pandas DataFrame of the articles returned from the API.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     articles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martlist\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m articles:\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(articles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Picar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gdeltdoc\\api_client.py:166\u001b[0m, in \u001b[0;36mGdeltDoc._query\u001b[1;34m(self, mode, query_string)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Response is text/html if it's an error and application/json if it's ok\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/html\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe query was not valid. The API error message was: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m load_json(response\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth_json_parsing)\n",
      "\u001b[1;31mValueError\u001b[0m: The query was not valid. The API error message was: Your query was too short or too long."
     ]
    }
   ],
   "source": [
    "gd = GdeltDoc()\n",
    "articles = gd.article_search(f)\n",
    "df = pd.DataFrame(articles)\n",
    "# con toda la lista de paises no es posible, sale error, habrá que hacerlos en bloques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nueva prueba, para ver CUANTOS PAISES A LA VEZ PODEMOS PONER EN EL FILTRO E INFORMAR A RANDBEE\n",
    "from gdeltdoc import GdeltDoc, Filters\n",
    "import pandas as pd\n",
    "f = Filters(\n",
    "    keyword=\"Inclusive growth\",\n",
    "    start_date=\"2018-05-10\", # Primero he puesto 2014, PERO ME DABA ERROR COMO SI DE ESTE TOPIC NO HUBIESE TODOS LOS AÑOS!!!  REVISAR ESTO!\n",
    "    end_date=\"2023-05-11\",\n",
    "    country = \"Czech Republic\")\n",
    "# Y EFECTIVAMENTE FALLA, BUSCAR ESTE NOMBRE EN GDELT!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The query was not valid. The API error message was: Invalid/Unsupported Country.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m gd \u001b[38;5;241m=\u001b[39m GdeltDoc()\n\u001b[1;32m----> 2\u001b[0m articles \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marticle_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(articles)\n",
      "File \u001b[1;32mc:\\Users\\Picar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gdeltdoc\\api_client.py:79\u001b[0m, in \u001b[0;36mGdeltDoc.article_search\u001b[1;34m(self, filters)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marticle_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, filters: Filters) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Make a query against the `ArtList` API to return a DataFrame of news articles that\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    match the supplied filters.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m        A pandas DataFrame of the articles returned from the API.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     articles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martlist\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m articles:\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(articles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Picar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gdeltdoc\\api_client.py:166\u001b[0m, in \u001b[0;36mGdeltDoc._query\u001b[1;34m(self, mode, query_string)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Response is text/html if it's an error and application/json if it's ok\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/html\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe query was not valid. The API error message was: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m load_json(response\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth_json_parsing)\n",
      "\u001b[1;31mValueError\u001b[0m: The query was not valid. The API error message was: Invalid/Unsupported Country."
     ]
    }
   ],
   "source": [
    "gd = GdeltDoc()\n",
    "articles = gd.article_search(f)\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nueva prueba, para ver CUANTOS PAISES A LA VEZ PODEMOS PONER EN EL FILTRO E INFORMAR A RANDBEE\n",
    "from gdeltdoc import GdeltDoc, Filters\n",
    "import pandas as pd\n",
    "f = Filters(\n",
    "    keyword=\"Inclusive growth\",\n",
    "    start_date=\"2018-05-10\", # Primero he puesto 2014, PERO ME DABA ERROR COMO SI DE ESTE TOPIC NO HUBIESE TODOS LOS AÑOS!!!  REVISAR ESTO!\n",
    "    end_date=\"2023-05-11\",\n",
    "    country = \"CZ\")\n",
    "# hacemos mas pruebas de republica checa, pero no funciona. lO INTENTAMOS EN ESPAÑOL, POR SEPARADO AMBAS PALABRAS, CON LAS SIGLAS FIPS\n",
    "# EN MAYUSCULA Y MINUSCULA, Y NADA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The query was not valid. The API error message was: Invalid/Unsupported Country.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m gd \u001b[38;5;241m=\u001b[39m GdeltDoc()\n\u001b[1;32m----> 2\u001b[0m articles \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marticle_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(articles)\n",
      "File \u001b[1;32mc:\\Users\\Picar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gdeltdoc\\api_client.py:79\u001b[0m, in \u001b[0;36mGdeltDoc.article_search\u001b[1;34m(self, filters)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marticle_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, filters: Filters) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Make a query against the `ArtList` API to return a DataFrame of news articles that\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    match the supplied filters.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m        A pandas DataFrame of the articles returned from the API.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     articles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martlist\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m articles:\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(articles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Picar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gdeltdoc\\api_client.py:166\u001b[0m, in \u001b[0;36mGdeltDoc._query\u001b[1;34m(self, mode, query_string)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Response is text/html if it's an error and application/json if it's ok\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/html\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe query was not valid. The API error message was: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m load_json(response\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth_json_parsing)\n",
      "\u001b[1;31mValueError\u001b[0m: The query was not valid. The API error message was: Invalid/Unsupported Country."
     ]
    }
   ],
   "source": [
    "gd = GdeltDoc()\n",
    "articles = gd.article_search(f)\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nueva prueba, para ver CUANTOS PAISES A LA VEZ PODEMOS PONER EN EL FILTRO E INFORMAR A RANDBEE,\n",
    "# ELIMINAMOS REPUBLICA CHECA POR ERROR ANTERIOR PERO ME SIGUE DANDO ERROR\n",
    "from gdeltdoc import GdeltDoc, Filters\n",
    "import pandas as pd\n",
    "f = Filters(\n",
    "    keyword=\"Inclusive growth\",\n",
    "    start_date=\"2018-05-10\", # Primero he puesto 2014, PERO ME DABA ERROR COMO SI DE ESTE TOPIC NO HUBIESE TODOS LOS AÑOS!!!  REVISAR ESTO!\n",
    "    end_date=\"2023-05-11\",\n",
    "    country = [\"Austria\",\"Belgium\",\"Switzerland\",\"Cyprus\",\"Germany\",\"Denmark\",\"Estonia\",\"Spain\"])\n",
    "# HEMOS ELIMINADO REPUBLICA CHECA PERO SIGUEN DANDO ERROR SI LOS PONEMOS TODOS, METEMOS 9 EN PRINCIPIO Y FUNCIONA\n",
    "# PROBAMOS 13 Y YA NO. 12 TAMPOCO. Tras las pruebas individuales, vemos que 9 es lo maximo que acepta este filtro.\n",
    "# INFORMAR A RANDBEE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = GdeltDoc()\n",
    "articles = gd.article_search(f)\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_mobile</th>\n",
       "      <th>title</th>\n",
       "      <th>seendate</th>\n",
       "      <th>socialimage</th>\n",
       "      <th>domain</th>\n",
       "      <th>language</th>\n",
       "      <th>sourcecountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.finanznachrichten.de/nachrichten-2...</td>\n",
       "      <td></td>\n",
       "      <td>The Mastercard Center for Inclusive Growth : H...</td>\n",
       "      <td>20230331T230000Z</td>\n",
       "      <td>https://www.finanznachrichten.de/chart-masterc...</td>\n",
       "      <td>finanznachrichten.de</td>\n",
       "      <td>English</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.finanznachrichten.de/nachrichten-2...</td>\n",
       "      <td></td>\n",
       "      <td>The Mastercard Center for Inclusive Growth : S...</td>\n",
       "      <td>20230321T160000Z</td>\n",
       "      <td>https://www.finanznachrichten.de/chart-masterc...</td>\n",
       "      <td>finanznachrichten.de</td>\n",
       "      <td>English</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.wallstreet-online.de/nachricht/167...</td>\n",
       "      <td>https://www.wallstreet-online.de/_amp/nachrich...</td>\n",
       "      <td>How Mastercard Is Advancing Inclusive Growth</td>\n",
       "      <td>20230331T230000Z</td>\n",
       "      <td>https://assets.wallstreet-online.de/_media/126...</td>\n",
       "      <td>wallstreet-online.de</td>\n",
       "      <td>English</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.finanznachrichten.de/nachrichten-2...</td>\n",
       "      <td></td>\n",
       "      <td>The Mastercard Center for Inclusive Growth : H...</td>\n",
       "      <td>20230417T191500Z</td>\n",
       "      <td>https://www.accesswire.com/users/newswire/imag...</td>\n",
       "      <td>finanznachrichten.de</td>\n",
       "      <td>English</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.finanznachrichten.de/nachrichten-2...</td>\n",
       "      <td></td>\n",
       "      <td>The Mastercard Center for Inclusive Growth : J...</td>\n",
       "      <td>20230316T201500Z</td>\n",
       "      <td>https://www.accesswire.com/users/newswire/imag...</td>\n",
       "      <td>finanznachrichten.de</td>\n",
       "      <td>English</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>https://www.finanznachrichten.de/nachrichten-2...</td>\n",
       "      <td></td>\n",
       "      <td>EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...</td>\n",
       "      <td>20230330T134500Z</td>\n",
       "      <td>https://eqs-cockpit.com/cgi-bin/fncls.ssp?fn=s...</td>\n",
       "      <td>finanznachrichten.de</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>https://www.boersennews.de/nachrichten/artikel...</td>\n",
       "      <td></td>\n",
       "      <td>IRW - News : First Class Metals Plc .: First C...</td>\n",
       "      <td>20230309T124500Z</td>\n",
       "      <td>https://media.boersennews.de/images/news/austi...</td>\n",
       "      <td>boersennews.de</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>https://www.openpr.de/news/1244427/Einsatz-von...</td>\n",
       "      <td></td>\n",
       "      <td>Einsatz von Nahrungsergänzungsmittel in Hochri...</td>\n",
       "      <td>20230426T090000Z</td>\n",
       "      <td>https://cdn.openpr.de/pressemitteilung/c/1/6/c...</td>\n",
       "      <td>openpr.de</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>https://www.nexotur.com/noticia/118383/colombi...</td>\n",
       "      <td>https://www.nexotur.com/mvc/amp/noticia/118383/</td>\n",
       "      <td>Colombia se define como un destino biodiverso ...</td>\n",
       "      <td>20230216T064500Z</td>\n",
       "      <td>https://www.nexotur.com/fotos/1/Arturo_Bravo_V...</td>\n",
       "      <td>nexotur.com</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>https://www.boersennews.de/nachrichten/artikel...</td>\n",
       "      <td></td>\n",
       "      <td>EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...</td>\n",
       "      <td>20230330T134500Z</td>\n",
       "      <td>https://media.boersennews.de/images/news/woman...</td>\n",
       "      <td>boersennews.de</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "0   https://www.finanznachrichten.de/nachrichten-2...   \n",
       "1   https://www.finanznachrichten.de/nachrichten-2...   \n",
       "2   https://www.wallstreet-online.de/nachricht/167...   \n",
       "3   https://www.finanznachrichten.de/nachrichten-2...   \n",
       "4   https://www.finanznachrichten.de/nachrichten-2...   \n",
       "..                                                ...   \n",
       "69  https://www.finanznachrichten.de/nachrichten-2...   \n",
       "70  https://www.boersennews.de/nachrichten/artikel...   \n",
       "71  https://www.openpr.de/news/1244427/Einsatz-von...   \n",
       "72  https://www.nexotur.com/noticia/118383/colombi...   \n",
       "73  https://www.boersennews.de/nachrichten/artikel...   \n",
       "\n",
       "                                           url_mobile  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2   https://www.wallstreet-online.de/_amp/nachrich...   \n",
       "3                                                       \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "69                                                      \n",
       "70                                                      \n",
       "71                                                      \n",
       "72    https://www.nexotur.com/mvc/amp/noticia/118383/   \n",
       "73                                                      \n",
       "\n",
       "                                                title          seendate  \\\n",
       "0   The Mastercard Center for Inclusive Growth : H...  20230331T230000Z   \n",
       "1   The Mastercard Center for Inclusive Growth : S...  20230321T160000Z   \n",
       "2        How Mastercard Is Advancing Inclusive Growth  20230331T230000Z   \n",
       "3   The Mastercard Center for Inclusive Growth : H...  20230417T191500Z   \n",
       "4   The Mastercard Center for Inclusive Growth : J...  20230316T201500Z   \n",
       "..                                                ...               ...   \n",
       "69  EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...  20230330T134500Z   \n",
       "70  IRW - News : First Class Metals Plc .: First C...  20230309T124500Z   \n",
       "71  Einsatz von Nahrungsergänzungsmittel in Hochri...  20230426T090000Z   \n",
       "72  Colombia se define como un destino biodiverso ...  20230216T064500Z   \n",
       "73  EQS - HV : DEUTSCHE BANK AKTIENGESELLSCHAFT : ...  20230330T134500Z   \n",
       "\n",
       "                                          socialimage                domain  \\\n",
       "0   https://www.finanznachrichten.de/chart-masterc...  finanznachrichten.de   \n",
       "1   https://www.finanznachrichten.de/chart-masterc...  finanznachrichten.de   \n",
       "2   https://assets.wallstreet-online.de/_media/126...  wallstreet-online.de   \n",
       "3   https://www.accesswire.com/users/newswire/imag...  finanznachrichten.de   \n",
       "4   https://www.accesswire.com/users/newswire/imag...  finanznachrichten.de   \n",
       "..                                                ...                   ...   \n",
       "69  https://eqs-cockpit.com/cgi-bin/fncls.ssp?fn=s...  finanznachrichten.de   \n",
       "70  https://media.boersennews.de/images/news/austi...        boersennews.de   \n",
       "71  https://cdn.openpr.de/pressemitteilung/c/1/6/c...             openpr.de   \n",
       "72  https://www.nexotur.com/fotos/1/Arturo_Bravo_V...           nexotur.com   \n",
       "73  https://media.boersennews.de/images/news/woman...        boersennews.de   \n",
       "\n",
       "   language sourcecountry  \n",
       "0   English       Germany  \n",
       "1   English       Germany  \n",
       "2   English       Germany  \n",
       "3   English       Germany  \n",
       "4   English       Germany  \n",
       "..      ...           ...  \n",
       "69   German       Germany  \n",
       "70   German       Germany  \n",
       "71   German       Germany  \n",
       "72  Spanish         Spain  \n",
       "73   German       Germany  \n",
       "\n",
       "[74 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a visualizar este ejemplo y que tipo de dataframe nos da\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Average Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-10 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-11 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-12 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-13 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-14 00:00:00+00:00</td>\n",
       "      <td>-0.6656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2023-05-07 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2023-05-08 00:00:00+00:00</td>\n",
       "      <td>2.5937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2023-05-09 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2023-05-10 00:00:00+00:00</td>\n",
       "      <td>-3.4895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2023-05-11 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      datetime  Average Tone\n",
       "0    2018-05-10 00:00:00+00:00        0.0000\n",
       "1    2018-05-11 00:00:00+00:00        0.0000\n",
       "2    2018-05-12 00:00:00+00:00        0.0000\n",
       "3    2018-05-13 00:00:00+00:00        0.0000\n",
       "4    2018-05-14 00:00:00+00:00       -0.6656\n",
       "...                        ...           ...\n",
       "1821 2023-05-07 00:00:00+00:00        0.0000\n",
       "1822 2023-05-08 00:00:00+00:00        2.5937\n",
       "1823 2023-05-09 00:00:00+00:00        0.0000\n",
       "1824 2023-05-10 00:00:00+00:00       -3.4895\n",
       "1825 2023-05-11 00:00:00+00:00        0.0000\n",
       "\n",
       "[1826 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para analizar el tono\n",
    "tone_results = gd.timeline_search(\"timelinetone\", f)\n",
    "tone_results\n",
    "# significado, LOS NEGATIVOS TIENEN TONOS NEGATIVOS, LOS POSITIVOS POSITIVOS Y LOS CERCANOS A CERO NEUTROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordemos que los datos son POR DIAS, habria que agrupar por semana y por trimestre!! (lo solicitado por randbee)\n",
    "# MUY IMPORTANTE QUE REGULARICEMOS BIEN, QUE NORMALICEMOS CORRECTAMENTE!! (con criterio igual que google trends y variable respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Volume Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-10 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-11 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-12 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-13 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-14 00:00:00+00:00</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2023-05-07 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2023-05-08 00:00:00+00:00</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2023-05-09 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2023-05-10 00:00:00+00:00</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2023-05-11 00:00:00+00:00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      datetime  Volume Intensity\n",
       "0    2018-05-10 00:00:00+00:00            0.0000\n",
       "1    2018-05-11 00:00:00+00:00            0.0000\n",
       "2    2018-05-12 00:00:00+00:00            0.0000\n",
       "3    2018-05-13 00:00:00+00:00            0.0000\n",
       "4    2018-05-14 00:00:00+00:00            0.0002\n",
       "...                        ...               ...\n",
       "1821 2023-05-07 00:00:00+00:00            0.0000\n",
       "1822 2023-05-08 00:00:00+00:00            0.0006\n",
       "1823 2023-05-09 00:00:00+00:00            0.0000\n",
       "1824 2023-05-10 00:00:00+00:00            0.0005\n",
       "1825 2023-05-11 00:00:00+00:00            0.0000\n",
       "\n",
       "[1826 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y para la popularidad\n",
    "popularity_results = gd.timeline_search(\"timelinevol\", f)\n",
    "popularity_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularidad:\n",
    "La popularidad mide la cantidad de menciones o cobertura de un tema en los artículos.\n",
    "En nuestra tabla, los valores en la columna “Volume Intensity” representan la popularidad relativa de los artículos en un intervalo de tiempo específico.\n",
    "Estos valores son proporcionales dentro del conjunto de artículos monitoreados por GDELT.\n",
    "Rango de Popularidad:\n",
    "Los valores en la columna “Volume Intensity” pueden variar entre 0 y 1.\n",
    "Un valor de 0.1839 significa que, en ese intervalo de tiempo, los artículos relacionados con el tema tenían una popularidad relativa del 18.39% en comparación con el total de artículos monitoreados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OJO, TENEMOS QUE REVISAR LOS FILTROS QUE SE NOS PIDIO, QUE TENGA MAS DE 500 PALABRAS, \n",
    "# tambien surgen dudas de lo de normalizarlos luego (¿¿solo entre los articulos seleccionados??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFORMACION RANDBEE NUEVO CAMBIO\n",
    "Los datos de Google Trends se debería descargar para el periodo \"weekly\", y que los datos diarios de GDELT se deberían agrupar mediante promediado a datos semanales. El modelo se construiría entonces con datos para los cuartos de año, generados a partir de los datos semanales de Google Trends y GDELT como promedios, y con los datos por cuarto de año de la variable respuesta. Posteriormente, una vez calibrado el modelo, se harían predicciones con el mismo sobre los datos semanales de Google Trends y de GDELT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
