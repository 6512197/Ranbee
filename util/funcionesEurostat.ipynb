{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_dfs_vacios(dfs_by_country):\n",
    "    # Crear una lista para almacenar los países con DataFrames vacíos\n",
    "    paises_con_dfs_vacios = []\n",
    "\n",
    "    # Iterar sobre el diccionario\n",
    "    for country, dfs in dfs_by_country.items():\n",
    "        # Verificar si ambas listas están vacías\n",
    "        if len(dfs[0]) == 0 and len(dfs[1]) == 0:\n",
    "            paises_con_dfs_vacios.append(country)\n",
    "    \n",
    "    return paises_con_dfs_vacios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dfs_preprocessed(dfs_by_country):\n",
    "    if not os.path.exists(\"../data/pre-processed\"):\n",
    "        os.makedirs(\"../data/pre-processed\")\n",
    "\n",
    "    # Iterar sobre las claves y valores del diccionario\n",
    "    for pais, dfs_pais in dfs_by_country.items():\n",
    "        i = 0\n",
    "        for df in dfs_pais:\n",
    "            # Generar el nombre del archivo CSV\n",
    "            if (i == 0):\n",
    "                nombre_archivo = f\"../data/pre-processed/foreigner_act_{pais}_M.csv\"\n",
    "                i = 1\n",
    "            else:\n",
    "            \n",
    "                nombre_archivo = f\"../data/pre-processed/foreigner_act_{pais}_F.csv\"\n",
    "        # Guardar el DataFrame como un archivo CSV\n",
    "        df.to_csv(nombre_archivo, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_df_processed(dfs_by_country):\n",
    "    if not os.path.exists(\"../data/processed\"):\n",
    "        os.makedirs(\"../data/processed\")\n",
    "\n",
    "    # Iterar sobre las claves y valores del diccionario\n",
    "    for pais, dfs_pais in dfs_by_country.items():\n",
    "        df1 = dfs_pais[0]\n",
    "        df1.reset_index(drop=True, inplace=True)\n",
    "        df2 = dfs_pais[1]\n",
    "        df2.reset_index(drop=True, inplace=True) \n",
    "        df1['year_month'] = pd.to_datetime(df1['year_month'])\n",
    "        df2['year_month'] = pd.to_datetime(df2['year_month'])\n",
    "    \n",
    "        # Encontrar la fecha mínima común entre los dos DataFrames\n",
    "        fecha_minima_comun = max(df1['year_month'].min(), df2['year_month'].min())\n",
    "        fecha_maxima_comun = min(df1['year_month'].max(), df2['year_month'].max())\n",
    "    \n",
    "        # Seleccionar el rango de filas basado en la fecha mínima común\n",
    "        nuevo_df1 = df1[df1['year_month'] >= fecha_minima_comun].reset_index(drop=True)\n",
    "        nuevo_df2 = df2[df2['year_month'] >= fecha_minima_comun].reset_index(drop=True)\n",
    "    \n",
    "        # Calcular la suma de las últimas columnas de df1 y df2\n",
    "        suma_ultimas_columnas = nuevo_df1.iloc[:, -1] + nuevo_df2.iloc[:, -1]\n",
    "    \n",
    "        # Añadir la serie resultante como una nueva columna llamada 'total' a df1\n",
    "        nuevo_df1['total'] = suma_ultimas_columnas.round(1)\n",
    "        #nuevo_df1 = nuevo_df1.drop_duplicates(subset=['year_month'])\n",
    "        nombre_archivo = f\"../data/processed/foreigners_act_{pais}_MyF.csv\"\n",
    "        indice_fecha_maxima = nuevo_df1['year_month'].idxmax()\n",
    "\n",
    "        res = nuevo_df1.iloc[:indice_fecha_maxima+1,7:]    \n",
    "        # Guardar el DataFrame como un archivo CSV\n",
    "        res.to_csv(nombre_archivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_dfs_con_valores_cero(dfs_by_country):\n",
    "    \"\"\"\n",
    "    Encuentra los df con mas del 50% de valores cero.\n",
    "\n",
    "    Parámetros:\n",
    "        dfs_by_country (dic): dccionario con dos dfs por pais, uno masculino y otro femenino.\n",
    "        \n",
    "\n",
    "    Retorna: key_to_delete (lista): lista de claves de pais con aquellos que cumplen la condicion\n",
    "   \"\"\"\n",
    "       \n",
    "    # Lista para almacenar las claves de los DataFrames que se eliminarán\n",
    "    keys_to_delete = []\n",
    "    \n",
    "    # Crear una copia de las claves del diccionario\n",
    "    keys_copy = list(dfs_by_country.keys())\n",
    "    \n",
    "    # Iterar sobre las claves del diccionario\n",
    "    for country in keys_copy:\n",
    "        dfs_pais = dfs_by_country[country]\n",
    "        for i, df in enumerate(dfs_pais):\n",
    "            # Calcular el porcentaje de valores cero en 'total_obs_value'\n",
    "            porcentaje_ceros = (df['total_obs_value'] == 0).mean() * 100\n",
    "            \n",
    "            # Verificar si el porcentaje de ceros es mayor al 50%\n",
    "            if porcentaje_ceros > 50:\n",
    "                # Agregar la clave del DataFrame a la lista de claves a eliminar\n",
    "                keys_to_delete.append(country)\n",
    "                break\n",
    "    \n",
    "        \n",
    "    return keys_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completar_series_trimestrales(ruta_carpeta):\n",
    "    \"\"\"\n",
    "    Completa series temporales trimestrales faltantes en archivos CSV ubicados en un directorio\n",
    "    de entrada y guarda las series completas en otro directorio.\n",
    "\n",
    "    Parámetros:\n",
    "        ruta_carpeta (str): La ruta al directorio que contiene los archivos CSV de series temporales.\n",
    "        \n",
    "    Retorna: None\n",
    "   \"\"\"\n",
    "    # Verificar si la carpeta de salida existe, si no, crearla\n",
    "    if not os.path.exists(\"../data/series\"):\n",
    "        os.makedirs(\"../data/series\")\n",
    "    \n",
    "    # Obtener la lista de archivos en la carpeta\n",
    "    archivos = os.listdir(ruta_carpeta)\n",
    "    \n",
    "    # Iterar sobre los archivos en la carpeta\n",
    "    for archivo in archivos:\n",
    "        # Verificar que el archivo es un archivo CSV\n",
    "        if archivo.endswith('.csv'):\n",
    "            # Construir la ruta completa al archivo\n",
    "            ruta_archivo = os.path.join(ruta_carpeta, archivo)\n",
    "            # Leer el archivo CSV\n",
    "            df = pd.read_csv(ruta_archivo)\n",
    "            # Convertir la columna 'year_month' a tipo datetime\n",
    "            df['year_month'] = pd.to_datetime(df['year_month'])\n",
    "            # Eliminar filas duplicadas si existen\n",
    "            df = df.drop_duplicates(subset=['year_month'])\n",
    "            # Obtener la menor y la mayor fecha presente en el DataFrame\n",
    "            min_fecha = df['year_month'].min()\n",
    "            max_fecha = df['year_month'].max()\n",
    "            # Crear una serie temporal mensual entre la menor y la mayor fecha\n",
    "            fechas_mensuales = pd.date_range(start=min_fecha, end=max_fecha, freq='Q')\n",
    "            # Crear un DataFrame vacío con las fechas mensuales como índice\n",
    "            df_mensual = pd.DataFrame(index=fechas_mensuales)\n",
    "            # Rellenar la serie temporal mensual con los valores del trimestre correspondiente\n",
    "            df_mensual['total'] = df.set_index('year_month').resample('Q').ffill()['total']\n",
    "            # Guardar el DataFrame reducido como un archivo CSV\n",
    "            ruta_nueva = os.path.join(\"../data/series\", archivo)\n",
    "            df_mensual.to_csv(ruta_nueva)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generar_serie_suma(directorio_entrada):\n",
    "    \"\"\"\n",
    "    Genera una serie con la suma de todas las series en archivos CSV ubicados en un directorio de entrada y guarda la serie resultante en un archivo CSV.\n",
    "\n",
    "    Parámetros:\n",
    "        directorio_entrada (str): La ruta al directorio que contiene los archivos CSV de las series a sumar.\n",
    "        archivo_salida (str): La ruta al archivo CSV donde se guardará la serie resultante.\n",
    "\n",
    "    Retorna:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leer los archivos en el directorio de entrada\n",
    "    archivos = os.listdir(directorio_entrada)\n",
    "    # Verificar si la carpeta de salida existe, si no, crearla\n",
    "    if not os.path.exists(\"../data/serie\"):\n",
    "        os.makedirs(\"../data/serie\")\n",
    "\n",
    "    # Inicializar una lista para almacenar las series individuales\n",
    "    series = []\n",
    "\n",
    "    # Leer los archivos en el directorio de entrada\n",
    "    archivos = os.listdir(directorio_entrada)\n",
    "\n",
    "    # Encontrar la serie con el mayor rango de fechas\n",
    "    fechas_maximas = pd.Series()\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(directorio_entrada, archivo)\n",
    "            df = pd.read_csv(ruta_archivo, index_col=0)\n",
    "            \n",
    "            # Encontrar las fechas únicas de esta serie y actualizar fechas_maximas si es necesario\n",
    "            fechas_actuales = pd.Series(df.index.unique())\n",
    "            if len(fechas_actuales) > len(fechas_maximas):\n",
    "                fechas_maximas = fechas_actuales\n",
    "\n",
    "    # Crear una serie con todas las fechas y total igual a cero\n",
    "    serie_vacia = pd.DataFrame(index=fechas_maximas, data={'total': 0})\n",
    "\n",
    "    # Sumar una a una las series temporales de cada país\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(directorio_entrada, archivo)\n",
    "            df = pd.read_csv(ruta_archivo, index_col=0)\n",
    "            \n",
    "            # Sumar la serie al DataFrame de la serie resultante\n",
    "            serie_vacia = serie_vacia.add(df, fill_value=0)\n",
    "\n",
    "    # Guardar la serie resultante en un archivo CSV\n",
    "    serie_vacia.to_csv('../data/serie/serie_EU.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
